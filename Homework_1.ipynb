{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "dataset_inspector": {
      "cols": {
        "lenName": 24,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "position": {
        "height": "110px",
        "left": "1185px",
        "right": "20px",
        "top": "108px",
        "width": "350px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l-baBf1Qb0i",
        "colab_type": "text"
      },
      "source": [
        "# CIS 545 - Big Data Analytics - Fall 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "qzbDVOuhZCo1",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "57127bfeccebf7eb7e910658b52aeb27",
          "grade": false,
          "grade_id": "cell-3a1d9a996b627af7",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "# Homework 1: Data Wrangling and Cleaning\n",
        "# Due Date: September 25, 2019 at 10pm\n",
        "\n",
        "We all know that cryptocurrencies are all the rage today.  Could we train an algorithm to tell the difference between a webpage about cryptocurrency and a webpage about something else?\n",
        "\n",
        "This initial assignment goes over some of the basic steps in (1) acquiring data from the web, (2) acquiring tabular data, (3) cleaning and linking data, and (4) training a simple machine learning classifer.  Along the way you'll learn a few of the basic tools, and get a very basic understanding of one way to represent documents.\n",
        "\n",
        "**Note: You do not need to connect your local runtime to do this assignment!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5CO9AOBUK-4",
        "colab": {}
      },
      "source": [
        "# Standard pip install...  Put all of your to-install packages here.\n",
        "# Depending on your configuration, you may need to change pip3 to pip\n",
        "#!pip install scrapy\n",
        "#!pip install lxml\n",
        "#!pip install scikit-learn\n",
        "#!pip install swifter\n",
        "#!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsqKccaWUK-7",
        "colab": {}
      },
      "source": [
        "# Standard imports; it's cleaner to put them here so they can be used\n",
        "# throughout the notebook\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lxml import etree\n",
        "import sqlite3\n",
        "import swifter\n",
        "import urllib\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk import classify\n",
        "from nltk import NaiveBayesClassifier\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "2d_SGrC0UK-8",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dc29aa53c704cada7f6e10ecf817db11",
          "grade": false,
          "grade_id": "cell-2ae3cd0ba764bf75",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Task 1: Acquiring data for training our system\n",
        "\n",
        "First let's get some information about what's a cryptocurrency.  For that -- there's always [Wikipedia](https://en.wikipedia.org/wiki/List_of_cryptocurrencies)!\n",
        "\n",
        "But of course it won't give us the data exactly the way we want it, so we'll need to do a bit of information extraction and data wrangling. We will also try to get current price levels from [Yahoo](https://finance.yahoo.com/cryptocurrencies)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "sJd7yCmSUK-9",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eba4f09eac3a10522253648aee781e87",
          "grade": false,
          "grade_id": "cell-b8d0a5f521360756",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Task 1.1: Fetch the list of pages from Wikipedia and put it into a dataframe\n",
        "\n",
        "First we'll get the master table of \"known\" cryptocurrencies. Use the `read_html()` function from `pandas`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "GinY-jklZTuc",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a8bb18ff7ac1ba34fabb39c5f4e4a9c5",
          "grade": false,
          "grade_id": "1-1-1-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# (1) Fetch files from Wikipedia:  https://en.wikipedia.org/wiki/List_of_cryptocurrencies\n",
        "# (2) Parse into a dataframe called cryptocurrency_df\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "cryptocurrency_df = pd.read_html('https://en.wikipedia.org/wiki/List_of_cryptocurrencies')[0]\n",
        "\n",
        "#raise NotImplementedError()\n",
        "\n",
        "display(cryptocurrency_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "dKvFl0yfikvN",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6328beb59b0529da85a1bcbcce280c0f",
          "grade": false,
          "grade_id": "cell-4774f393116f5d10",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Next, do the same for the following two sites. Yahoo gives a maximum of 100 prices at a time, so this is why we have to have two queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "hPCMExmNUK-_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "961bcad9a4eae11a5131f86ccc9e3a69",
          "grade": false,
          "grade_id": "1-1-2-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Make two price dataframes from\n",
        "# price_1_df: https://finance.yahoo.com/cryptocurrencies/?count=100&offset=0\n",
        "# price_2_df: https://finance.yahoo.com/cryptocurrencies/?count=100&offset=100\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "price_1_df = pd.read_html('https://finance.yahoo.com/cryptocurrencies/?count=100&offset=0')[0]\n",
        "price_2_df = pd.read_html('https://finance.yahoo.com/cryptocurrencies/?count=100&offset=100')[0]\n",
        "\n",
        "#raise NotImplementedError()\n",
        "\n",
        "price_df = price_1_df.append(price_2_df)\n",
        "\n",
        "display(price_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "VSSXMhqSUK_B",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4c7f290f0a7682c1c857c163b40692d2",
          "grade": true,
          "grade_id": "1-1-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Quick sanity check 1.1 for cryptocurrency_df: does it have the columns from the Wikipedia table?\n",
        "\n",
        "if not 'Currency' in cryptocurrency_df:\n",
        "    raise AssertionError('Expected column called \"Currency\"')\n",
        "    \n",
        "if not 'Founder(s)' in cryptocurrency_df:\n",
        "    raise AssertionError('Expected column called \"Founder(s)\"')\n",
        "\n",
        "display(cryptocurrency_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "7ZzszWRuUK_C",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "788af1559311bcf58e44625de1706520",
          "grade": true,
          "grade_id": "1-1-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.1 for autograding cryptocurrency_df - don't delete this cell please!\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "2P0K5eVJUK_E",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "82866152a78acf7786154ee380d252b2",
          "grade": false,
          "grade_id": "cell-e102b6da0afa92b9",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Task 1.2 First bit of data Cleaning:  Clean up the schema names.\n",
        "\n",
        "It turns out that SQL databases often don't like parentheses and spaces in the column names.  Change the column names for the appropriate columns, by \n",
        "\n",
        "1. removing the parts in parentheses\n",
        "2. trimming any blank spaces before or after the names\n",
        "3. inserting underscores for spaces.  \n",
        "\n",
        "Hint: there are functions called `trim`, `strip`, `find`, `replace`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "9gs7SsqkUK_F",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f717c4ceb1525a196b5f6dbdc32667bf",
          "grade": false,
          "grade_id": "1-2-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# For all column names in cryptocurrency_df, \n",
        "# (1) remove anything in parentheses, \n",
        "# (2) remove leading and trailing spaces, \n",
        "# (3) replace remaining spaces with underscores\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "##1. remove the parts in parantheses\n",
        "\n",
        "cryptocurrency_df.columns = cryptocurrency_df.columns.str.replace(r\"\\(.*\\)\",\"\")\n",
        "\n",
        "##2. remove leading and trailing spaces\n",
        "\n",
        "cryptocurrency_df.columns = cryptocurrency_df.columns.str.strip()\n",
        "\n",
        "##3. replace remaining spaces with underscores\n",
        "\n",
        "cryptocurrency_df.columns = cryptocurrency_df.columns.str.replace(\" \",\"_\")\n",
        "\n",
        "#raise NotImplementedError()\n",
        "#cryptocurrency_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "2BUupYbJUK_G",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da1adf754aa89780fce9e905bf692a5",
          "grade": true,
          "grade_id": "1-2-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.2 for cryptocurrency_df\n",
        "\n",
        "for column in cryptocurrency_df.keys():\n",
        "    if column.find(' ') >= 0:\n",
        "        raise AssertionError('Forgot to remove a space in \"%s\"'%column)\n",
        "    elif column.find('(') >= 0 or column.find(')') >= 0:\n",
        "        raise AssertionError('Forgot to remove a paren in %s'%column)\n",
        "        \n",
        "display(cryptocurrency_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "NJ4fLEeNUK_I",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1386e6222287306c3a47b3c71d548e19",
          "grade": true,
          "grade_id": "1-2-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.2 for autograding cryptocurrency_df - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "nAhUmsLkXwki",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b569bf46e7697a9509f3d8da0ccb8dee",
          "grade": false,
          "grade_id": "cell-f43f3351c585fae7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.3: Joining the tables\n",
        "\n",
        "We are now going to try to put these two sources of information into one table. The requirement is that we want to make sure that we have an entry for every currency in the Wikipedia list, but not necessarily for every currency in the Yahoo price list. Of the four types of join, two can achieve this requirement. For extra practice, see if you can figure out both correct answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "lyL-QyurHZk5",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2ff0bac8b2840dc04a589a6ca5e331f6",
          "grade": false,
          "grade_id": "cell-7731a5ca51f701cc",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Task 1.3.1 Attempt #1\n",
        "\n",
        "In the cell below, join `cryptocurrency_df` and `price_df` using \"Name\" as the join index of `price_df` and \"Currency\" as the join index of `cryptocurrency_df`. The result should be named `joined_on_name_df`. Do not make any changes to the data frames yet, even though you may see a problem with joining them now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "T0l2d7cI4mTZ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4802ba43c67ea0c19d654156dca30677",
          "grade": false,
          "grade_id": "1-3-1-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Join cryptocurrency_df and price_df\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "joined_on_name_df = cryptocurrency_df.merge(price_df, left_on = \"Currency\", right_on = \"Name\")\n",
        "\n",
        "#raise NotImplementedError()\n",
        "\n",
        "display(joined_on_name_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "-XBBxAANah8Q",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "abe2f2f7f530e194a17ec03c5898f356",
          "grade": true,
          "grade_id": "1-3-1-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.3.1 for joined_on_name_df\n",
        "\n",
        "if len(joined_on_name_df.columns) != 20:\n",
        "    raise AssertionError('Your joined table has %d columns, an unexpected number.'%len(joined_on_name_df.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "m9pO1Ckib7v_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5a94a419d3651a83b7fe3fd3b3e040aa",
          "grade": true,
          "grade_id": "1-3-1-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.3.1 for autograding joined_on_name_df - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "dtD8KovehXDW",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "15d8ebba7b79db4537f6643886d37807",
          "grade": false,
          "grade_id": "cell-05ab54359c83552b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Task 1.3.2 Cleaning up the names\n",
        "\n",
        "You may have noticed a mismatch for how the currencies are named between the two data frames. Use the `apply` function to replace the values in the `price_df[\"Name\"]` column so they better match the values in `cryptocurrency_df[\"Currency\"]`.\n",
        "\n",
        "Then rerun your join from 1.3.1 and name it the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "5gc1aizt5DHN",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4b0be3955ca0a9a9be7c2fce4ac61e24",
          "grade": false,
          "grade_id": "1-3-2-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Remove Fix Name column in price_df and redo the join\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "price_df[\"Name\"] = price_df[\"Name\"].apply(lambda x: x.replace(\" USD\",\"\"))\n",
        "\n",
        "#raise NotImplementedError()\n",
        "\n",
        "display(joined_on_name_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "d6vi4TjHki1L",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "98bdf1beea84d6c53bea894c6bbdc4ab",
          "grade": true,
          "grade_id": "1-3-2-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.3.2 for joined_on_name_df\n",
        "\n",
        "if len(joined_on_name_df[joined_on_name_df[\"Name\"].notna()]) == 0:\n",
        "    raise AssertionError('Your join did not find any matches. Maybe you did something wrong?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "lL_TLxsskjHz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "23ab3e1e6a7fc4e4beb05d28e8792463",
          "grade": true,
          "grade_id": "1-3-2-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.3.2 for autograding joined_on_name_df cleaned - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "YQw49TttUK_K",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "385974619367955c4f6fbbfc60e211f4",
          "grade": false,
          "grade_id": "cell-e2ba62e3ef673b7e",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Task 1.3.3: Clean the citations out of the content.\n",
        "\n",
        "As we saw in lecture, the html processing function converts Wikipedia citations to normal text. You may have noticed that this is keeping at least one of the cryptocurrencies from matching during the join. In the cell below, use `applymap` to remove these citations from the entire `cryptocurrency_df` table. Assume that every instance of \"`[`\" begins a citation. In this case only, it is okay if you delete everything after the \"`[`\", including the stuff after \"`]`\".\n",
        "\n",
        "Then rerun your join from 1.3.2 and name it the same way. Did you get more matches?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "yJvV8EHRUK_K",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8e374581414b8734b63e22bb0c12b187",
          "grade": false,
          "grade_id": "1-3-3-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO: Remove citations\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        " cryptocurrency_df = cryptocurrency_df.applymap(lambda y: re.sub(\"\\[.*?\\]\",\"\",str(y)))\n",
        "\n",
        "#raise NotImplementedError()\n",
        "\n",
        "display(joined_on_name_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "Dxxobixjo9FK",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0b378d0669b965f6fb9c8f44792fdb60",
          "grade": true,
          "grade_id": "1-3-3-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.3.3 for joined_on_name_df\n",
        "\n",
        "print(\"%d matches found\"%len(joined_on_name_df[joined_on_name_df[\"Name\"].notna()]))\n",
        "if len(joined_on_name_df[joined_on_name_df[\"Name\"].notna()]) == 0:\n",
        "    raise AssertionError('Your join did not find any matches. Maybe you did something wrong?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "AeUsK_dvUK_N",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e8c50104a805207c36df5da0d8f1b072",
          "grade": true,
          "grade_id": "1-3-3-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.3.3 for autograding citation deletion - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "nXI3K1gzlkf6",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fa9856f9a3141de682cff5f5440649ea",
          "grade": false,
          "grade_id": "cell-25c55ba9e3bbb3eb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Task 1.3.4 A Better Column\n",
        "\n",
        "Look again at `cryptocurrency_df` and `price_df` and select better columns for indexing the join. Consider an `apply` function for the relevant column in `cryptocurrency_df` and for the relevant column in price_df` that you select. \n",
        "\n",
        "Name this table `joined_df`. To get the points for this section, you need to match at least as many currencies as our solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "bdy82NVn8JCe",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b4fd5cf9cd7892dfe7639989f871a6c3",
          "grade": false,
          "grade_id": "1-3-4-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Improve the join by switching to different columns\n",
        "\n",
        "# We will try to use attribute \"Symbol\"\n",
        "\n",
        "# YOUR CODE HERE\n",
        "\n",
        "cryptocurrency_df[\"Symbol\"] = cryptocurrency_df[\"Symbol\"].apply(lambda z: z.split(\",\")[0])\n",
        "price_df[\"Symbol\"] = price_df[\"Symbol\"].apply(lambda k: k.split(\"-\")[0])\n",
        "\n",
        "joined_df = cryptocurrency_df.merge(price_df, on=\"Symbol\")\n",
        "\n",
        "#raise NotImplementedError()\n",
        "\n",
        "display(joined_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "yEwuI4AwUK_M",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "504cd75c6ffa763d331b45b00ffb6417",
          "grade": true,
          "grade_id": "1-3-4-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.3.4 for joined_df\n",
        "\n",
        "print(\"%d matches found\"%len(joined_df[joined_df[\"Name\"].notna()]))\n",
        "if len(joined_df[joined_df[\"Name\"].notna()]) <= len(joined_on_name_df[joined_on_name_df[\"Name\"].notna()]):\n",
        "    raise AssertionError('Your new join is not better than the old one. Maybe you did something wrong?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "kDkBKD1vpsjo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b5220a1451a7be0e564b1ca1a3d36eb",
          "grade": true,
          "grade_id": "1-3-4-test",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.3.4 for autograding joined_df  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "SyIpJioCUK_O",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fd318eacc88cd523940f311a3ba569d8",
          "grade": false,
          "grade_id": "cell-2d67034b9182d155",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Task 1.4: Save the cryptocurrency list in a database table\n",
        "\n",
        "We don't want to continue to hit Wikipedia.org every time we want to consult the list of cryptocurrencies.  Save your `cryptocurrency_df` to sqlite, in a table called `cryptocurrency`.  \n",
        "\n",
        "**The Dataframe `index` has no particular meaning, so don't save it!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "lBouXUwPUK_P",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "17a26be73399ec67314b2e4d8e407bcb",
          "grade": false,
          "grade_id": "1-4-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO: convert cryptocurrency_df to sqlite\n",
        "\n",
        "conn = sqlite3.connect('local.db')\n",
        "\n",
        "# YOUR CODE HERE\n",
        "cryptocurrency_df.to_sql(\"cryptocurrency\", conn, if_exists=\"replace\", index = False)\n",
        "\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "OxxmLlveUK_Q",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d27749b16eca3815c502d1931efb8de8",
          "grade": true,
          "grade_id": "1-4-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.4 for sqlite databases\n",
        "\n",
        "crypto2 = pd.read_sql_query('select * from cryptocurrency', conn)\n",
        "\n",
        "if 'index' in crypto2:\n",
        "    raise AssertionError('Please disable the index, since it isn\\'t important information')\n",
        "    \n",
        "display(crypto2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "hQj8kQDZUK_S",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8c79b0870a69c620e5db812efd2b9125",
          "grade": false,
          "grade_id": "cell-2d7887a3456d8c6e",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Task 1.5: Read the cryptocurrency pages\n",
        "\n",
        "Now let's take each of the cryptocurrency names and find the associated URL. The names of the currencies were originally clickable links on the [webpage](https://en.wikipedia.org/wiki/List_of_cryptocurrencies) that we made the table from, but unfortunately, `pandas` automatically deleted the URLs. So we have to regenerate them. Feel free to look at that page to see what the correct URL is for each currency.\n",
        "\n",
        "In the cell below, complete the function `crawl`. The function name, inputs, first line, and last line are provided for you. \n",
        "\n",
        "`list_of_urls` should contain the URLs of interest as a list, column of a pandas DataFrame, or some other iterable over strings. \n",
        "\n",
        "`prefix` contains a common string that should be added to the beginning every URL in `list_of_urls` before each URL is queried. \n",
        "\n",
        "The line `pages = {}` creates an empty dictionary. After running your part of the function `crawl`, `pages` should have currency names as its keys and the corresponding Wikipedia page contents as its values. This is what the function returns.\n",
        "\n",
        "You have two options for completing this cell:\n",
        "\n",
        "1. If you want to use `urllib.request.urlopen`, you should then use `read()` and `decode('utf-8')`.\n",
        "\n",
        "2. If you want to use `scrapy`, follow the process in [this notebook from class](https://www.google.com/url?q=https://drive.google.com/file/d/1VfnlGr_VofdcEqACM2jRu2BwYm0QyTSh/view?usp%3Dsharing&sa=D&ust=1567968915286000&usg=AFQjCNG5iEWgUoA3DrRLhV1TKiT2OXHD1A).\n",
        "\n",
        "For now, use a `try` statement to catch the errors and print a message that the URL could not be crawled. That is, in this cell we will have a **single rule** and not do any manual cleaning.  If you were doing this at web scale, you would be reluctant to invest a lot of manual effort..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "KWhAXKtIUK_S",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e814b0d6adeaa837ce438ef3200fcc3c",
          "grade": false,
          "grade_id": "1-5-1-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO: Crawl the pages.  \n",
        "# Trap the errors and figure out what you need to fix (in the cleaning step below)\n",
        "\n",
        "def crawl(list_of_urls, prefix=\"\"):\n",
        "    pages = {}\n",
        "# YOUR CODE HERE\n",
        "    for url in list_of_urls:\n",
        "      try:\n",
        "        pages[url] = str(urllib.request.urlopen(prefix + url).read().decode('utf-8'))\n",
        "        print(prefix + url) #To check if the url makes sense(e.g. bitcoin cash)\n",
        "      except:\n",
        "        print(url + \"'s URL doesn't work\")       \n",
        "    return pages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "DyXjnGwJd_3S",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "817602c34603b02a17f289d644cec608",
          "grade": false,
          "grade_id": "cell-3723646eda1946ab",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The following cell passes the currencies in our table to the `crawl` function. You do not need to modify the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "sOV0Ic68UK_U",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5e18909ed5d515c265f72842e2783385",
          "grade": true,
          "grade_id": "1-5-1-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.5.1 for initial crawl\n",
        "# I modify it to see the values, or we cant see if something is wrong using my error-handling function\n",
        "\n",
        "pages = crawl(cryptocurrency_df['Currency'], 'https://en.wikipedia.org/wiki/')\n",
        "for page in pages:\n",
        "    print (page)\n",
        "print ('Total crawl: %d cryptocurrencies'%len(pages))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "3m9iHY0PsuuC",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c55e691154848b1b8c9e2e13f3b7db70",
          "grade": true,
          "grade_id": "1-5-1-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.5.1 for autograding pages  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "zwcnmQUhUK_X",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1f19f03e916ba2c96fad600508a89aaa",
          "grade": false,
          "grade_id": "cell-deb0ffb9e533fb7a",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "Did you get any errors? Did you ever get the wrong URL (and therefore the content from the wrong page)? Fix those two problems in the function `crawl_better` below. This function has the same inputs and outputs as `crawl`, but this time, it is okay if your fixes are specific to these sites. For example, you can try attaching `_(disambiguation)`, pull up that page's `etree.HTML(content)` and look for a link that has the name of the currency plus `' (cryptocurrency)'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "LE2T3xjPUK_Y",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "063fe1a4e9b0162282296f114a5ec4ae",
          "grade": false,
          "grade_id": "1-5-2-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO: Re-run the crawl, fixing the issues\n",
        "\n",
        "# Crawl the pages.  You may use urllib.request.urlopen or scrapy\n",
        "# Assemble the list of results in the list pages.\n",
        "# Trap the errors and figure out what you need to fix (in the cleaning step below)\n",
        "\n",
        "def crawl_better(list_of_urls, prefix=\"\"):\n",
        "    pages = {}\n",
        "# YOUR CODE HERE\n",
        "    for url in list_of_urls:\n",
        "      url = url.replace(\" \",\"_\")\n",
        "      url = url.replace(\"\\\"\",\"\")\n",
        "      try:\n",
        "        if url == \"Ripple\":\n",
        "          url = \"Ripple_(payment_protocol)\"\n",
        "        if url == \"Dash\":\n",
        "          url = \"Dash_(cryptocurrency)\"\n",
        "        if url == \"Monero\":\n",
        "          url = \"Monero_(cryptocurrency)\"\n",
        "        if url == \"NEM\":\n",
        "          url = \"NEM_(cryptocurrency)\"\n",
        "        if url == \"Verge\":\n",
        "          url = \"Verge_(cryptocurrency)\"\n",
        "        if url == \"Stellar\":\n",
        "          url = \"Stellar_(payment_network)\"\n",
        "        if url == \"Tether\":\n",
        "          url = \"Tether_(cryptocurrency)\"\n",
        "        if url == \"Ether_or_Ethereum\":\n",
        "          url = \"Ethereum\"\n",
        "        pages[url] = str(urllib.request.urlopen(prefix + url).read().decode('utf-8'))\n",
        "        print(prefix + url)\n",
        "      except:\n",
        "        print(url + \"'s URL doesn't work!!\")\n",
        "    return pages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "89GQIhVegj8u",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9f0af79e6101466ffaa7be8bfbd185ab",
          "grade": false,
          "grade_id": "cell-63b0ed2d452d5c9d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As before, the cell below just runs your function and does not need to be modified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "02DhGSKtgf1I",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a1e928ecf6b4f0a2d7ebe05283816eca",
          "grade": true,
          "grade_id": "1-5-2-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 1.5.2 for better crawl\n",
        "pages = crawl_better(cryptocurrency_df['Currency'], 'https://en.wikipedia.org/wiki/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "_rcNAmuvtTX1",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1f644ef71c675bc6c819a58fd2c36e13",
          "grade": true,
          "grade_id": "1-5-2-test",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.5.2 for autograding pages  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dqI_camUUK_c"
      },
      "source": [
        "### Task 1.6: Sanity-check and fix\n",
        "\n",
        "Note that sometimes terms in Wikipedia are **ambiguous**, so just following the page doesn't always get what you want.  The Wikipedia page for [Tether](https://en.wikipedia.org/wiki/Tether) does not describe a cryptocurrency.\n",
        "\n",
        "We can add a data-cleaning rule to check this: every cryptocurrency should mention the term \"blockchain\".  Here's a sanity check you can use.  If there are any disambiguation pages, you need to go back to Task 1.5 and update your process to crawl the right page.\n",
        "\n",
        "You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "wbd9_N5OUK_d",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d31d9334ec337b3752a857f241eef6f8",
          "grade": true,
          "grade_id": "1-6-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "count_wrong = 0\n",
        "\n",
        "for page,content in pages.items():\n",
        "    if isinstance(content, bytes):\n",
        "        raise AssertionError('Please run decode(\\'utf-8\\') on the content to decode to a string')\n",
        "        content = content.decode('utf-8')\n",
        "        \n",
        "    if 'blockchain' not in content:\n",
        "        print(page + ': ' + ' -- did not find blockchain!')\n",
        "        count_wrong = count_wrong + 1\n",
        "\n",
        "        \n",
        "print ('Total crawl: %d cryptocurrencies'%len(pages))\n",
        "\n",
        "if count_wrong > 0:\n",
        "    raise AssertionError('Need to follow Wikipedia disambiguation pages on %d items!'%count_wrong)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "zHSdtQFwNDxe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a650984d4c28f12b62877198869cbc40",
          "grade": false,
          "grade_id": "cell-1e1c896f1e786b55",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 1.7: Clean the articles\n",
        "\n",
        "So far, we have captured HTML content for each Wikipedia article, but HTML is not very easy to read and process. So the next step is to clean up the text in each article. To do that, you need to complete the function definition below. The function name, and input are provided for you. \n",
        "\n",
        "The first step is to get a list of paragraphs of content. See our [slides](https://www.google.com/url?q=https://drive.google.com/a/seas.upenn.edu/file/d/163sCi0h5RJAXynE1Vo37bAQtOvcwW_wv/view?usp%3Dsharing&sa=D&ust=1567968915286000&usg=AFQjCNGDBY3SNFEJIh3m5k7GyYmhK2Q52w) on xpath for hints. Then, for each word (string between whitespace characters):\n",
        "\n",
        "1. Remove the leading and trailing whitespace using `strip()`\n",
        "2. Remove the word entirely if it is only white space.\n",
        "3. Remove the word entirely if it is only numerics (you may use `isnumeric()` to test for this).\n",
        "\n",
        "Finally join the words together into one string with spaces in between using `' '.join()`. The function should return that string (output)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "v_7ihaxdUK_i",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "071c9c06645d38dad2618e8db0cb5efe",
          "grade": false,
          "grade_id": "1-7-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# TODO: Complete the clean_article function, as described above.\n",
        "\n",
        "def clean_article(content):\n",
        "  paragraph = etree.HTML(content).xpath(\"//p//text()\")\n",
        "#Remove the leading and trailing whitespace using strip()\n",
        "#Remove the word entirely if it is only white space.\n",
        "#Remove the word entirely if it is only numerics (you may use isnumeric() to test for this).\n",
        "  word_list = []\n",
        "  for word in paragraph:\n",
        "    word = word.strip()\n",
        "    word = word.replace(\"\\n\",\"\")\n",
        "    word = word.replace(\"\\t\",\"\")\n",
        "    if (word == \" \") or (word.isnumeric() == True):\n",
        "      word = \"\"\n",
        "    word_list.append(word)\n",
        "  return ' '.join(word_list)\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "s-N_8GpJW36n",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "787b3fbf9ee5774e813f83c303d4c017",
          "grade": false,
          "grade_id": "cell-207fe106eb600a6a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The following cell assembles our cleaned articles into a DataFrame. You do not need to modify the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "A5mnrUVgUK_j",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "be42569383ef2d8aa453f71cf8acdba3",
          "grade": true,
          "grade_id": "1-7-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "pages2 = []\n",
        "for currency_name, content in pages.items():\n",
        "    article = clean_article(content)\n",
        "    pages2.append({'currency': currency_name, 'text': article})\n",
        "pages_df = pd.DataFrame(pages2)\n",
        "\n",
        "display(pages_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "ZIFB-fi0vh-2",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "faa0e63a62d5211fd3af66cededd276b",
          "grade": true,
          "grade_id": "1-7-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 1.7 for autograding clean_article  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "CUVvKypxUK_n",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bedde93bec7a5fe09208ab99de4e6adb",
          "grade": false,
          "grade_id": "cell-6e036ee47472985f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Task 2: Build and run the classifier\n",
        "\n",
        "Now that we have the cryptocurrency articles processed, it is time to return to the original task of building a classifier that can identify cryptocurrency articles.\n",
        "\n",
        "## Task 2.1: Get the negative examples.\n",
        "\n",
        "If we want to build a (supervised) machine learning algorithm to detect content, we need both *positive* and *negative* examples.  In fact we want each successive training example to have an equal probability of being positive or negative.\n",
        "\n",
        "The following cell runs your `crawl` function from Task 1.5 and your `clean_article` function from Task 1.7. Note: We are using `crawl` not `crawl_better` because you may have included data-specific choices in `crawl_better` that are no longer true.\n",
        "\n",
        "You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "X0JB8G_mUK_o",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d4bb75b1a4e3ea045e9419e0c2e2f3aa",
          "grade": true,
          "grade_id": "2-1-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "training = [\n",
        "    'https://en.wikipedia.org/wiki/Tim_Cook',\n",
        "    'https://en.wikipedia.org/wiki/The_Great_British_Bake_Off',\n",
        "    'https://en.wikipedia.org/wiki/Google',\n",
        "    'https://en.wikipedia.org/wiki/Chan_Zuckerberg_Initiative',\n",
        "    'https://en.wikipedia.org/wiki/Politics',\n",
        "    'https://en.wikipedia.org/wiki/Fake_news',\n",
        "    'https://www.snopes.com/fact-check/social-media-hacker-warning/',\n",
        "    'https://www.cnn.com/2019/08/31/us/dorian-animals-foster-release-wxc/index.html',\n",
        "    'https://www.foxnews.com/us/indiana-dispatcher-helps-boy-who-called-911-with-fractions-homework',\n",
        "    'https://www.usatoday.com/story/tech/talkingtech/2019/08/31/hello-iphone-11-new-features-we-want-apple-next-models/2153565001/',\n",
        "    'http://theconversation.com/bury-fc-the-economics-of-an-english-football-clubs-collapse-122727',\n",
        "    'https://fivethirtyeight.com/features/economists-are-bad-at-predicting-recessions/'\n",
        "]\n",
        "\n",
        "negative = crawl(training)\n",
        "negative2 = []\n",
        "for site, content in negative.items():\n",
        "    article = clean_article(content)\n",
        "    negative2.append({'site': site, 'text': article})\n",
        "\n",
        "negative_df = pd.DataFrame(negative2)\n",
        "display(negative_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "MHF0VgEUUK_r",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4d07b6d3494f637f59051320b355fad4",
          "grade": false,
          "grade_id": "cell-62cfcdeb3e015663",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2.2: Process Document Text\n",
        "\n",
        "Right now, each Wikipedia article is a single string. This means, we only have one \"feature\" for the classifier. This is not enough. Tokenization (splitting up the article into words) would transform the data so that we have one feature per word. This probably would give us enough features to train a classifier.\n",
        "\n",
        "Complete the `get_words` function in the cell below. This function should take a string as input (the raw article).\n",
        "\n",
        "1. Create an empty list to store the good words.\n",
        "\n",
        "1. Break the article into sentences using the NLTK sentence tokenizer.\n",
        "\n",
        "1. Tokenize and part-of-speech tag each sentence.\n",
        "\n",
        "1. Run the provided `clean_word` function and Porter stemmer on each word.\n",
        "\n",
        "1. Finally, append the word stem to the list of good words if all of the following are true:\n",
        "    1. The word stem is of nonzero length.\n",
        "    2. The word stem has a length less than 20.\n",
        "    3. The word stem is not a stopword.\n",
        "    4. The word is a noun.\n",
        "    5. The word stem is in `vocabulary`. Only apply this rule if `vocabulary` has nonzero length. It has zero length by default.\n",
        "\n",
        "6. Return the list of good words.\n",
        "\n",
        "To match our solution, it is important that you do these steps in the given order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "eRBEZNakzHaE",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5188b69df96f7eaaee813ecb68eb694",
          "grade": false,
          "grade_id": "2-2-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Complete the get_words function\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "sw = set(stopwords.words(\"english\"))\n",
        "sw.add(\"'s\")\n",
        "stemmer = PorterStemmer()\n",
        "noun_tag = [\"NN\",\"NNP\",\"NNP\",\"NNPS\"]\n",
        "def clean_word(word):\n",
        "    word = word.lower()\n",
        "    word2 = ''\n",
        "    for w in word:\n",
        "        if w.isalpha() or (len(word2) > 0 and w.isnumeric()):\n",
        "            word2 = word2 + w\n",
        "    return word2\n",
        "\n",
        "def get_words(article, vocabulary=[]):\n",
        "  #Create an empty list to store the good words.\n",
        "  good_words = []\n",
        "  sentences = nltk.sent_tokenize(article)\n",
        "  for sentence in sentences:\n",
        "    tweet_tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True)\n",
        "    sentence = nltk.pos_tag(tweet_tokenizer.tokenize(sentence))\n",
        "    for word in sentence:\n",
        "      w = clean_word(word[0])\n",
        "      tag = word[1]\n",
        "      stem_word = stemmer.stem(w)\n",
        "      if(len(stem_word) != 0) and (len(stem_word) <20) and (stem_word not in sw) and (tag in noun_tag):\n",
        "        if (stem_word not in good_words):\n",
        "          if (len(vocabulary) > 0):\n",
        "              if(stem_word in vocabulary):\n",
        "                good_words.append(stem_word)\n",
        "          else:\n",
        "              good_words.append(stem_word)\n",
        "  return good_words\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "2vxeAJBcAQBc",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "21c6886fb673daa034fd56185b83d557",
          "grade": true,
          "grade_id": "2-2-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 2.2 for getting the word stems from articles\n",
        "\n",
        "print(get_words(\"to be or not to be\"))\n",
        "print(get_words(\"He wants to test the functionality of xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx in article 091019.\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "EAmUL-bXBhl5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "42f5e583642464ca84faa69403f00b37",
          "grade": true,
          "grade_id": "2-2-test",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 2.2 for autograding get_words  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "N4H2uByrC1AA",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "21ef74d1dabb994b0d49d4c60346dc69",
          "grade": false,
          "grade_id": "cell-eb6d77467ec87070",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2.3 Train the classifier\n",
        "\n",
        "Adapt the code from the NLTK lecture notebook to complete the `build_classifier` function. This function takes as input the two column dataframes `positive_df` and `negative_df`, and also an optional vocabulary list. It should run `get_words` on each article in each dataframe, get a frequency distribution from NLTK for each article, assemble the training set for a Naive Bayes classifier in the correct format, train the classifier, and return the trained classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "0YbN1Adx6Zng",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cf80b7cdea908493b4167e34121f6700",
          "grade": false,
          "grade_id": "2-3-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Complete the build_classifier function\n",
        "\n",
        "from nltk import classify\n",
        "from nltk import NaiveBayesClassifier\n",
        "\n",
        "def build_classifier(positive_df, negative_df, vocabulary=[]):\n",
        "# YOUR CODE HERE\n",
        "  positive_df_set = []\n",
        "  negative_df_set = []\n",
        "  for article_pos in positive_df['text']:\n",
        "    words = get_words(article_pos, vocabulary)\n",
        "    positive_df_set.append((nltk.FreqDist(words),'positive'))\n",
        "  for article_neg in negative_df['text']:\n",
        "    words = get_words(article_neg, vocabulary)\n",
        "    negative_df_set.append((nltk.FreqDist(words), 'negative'))\n",
        "  return NaiveBayesClassifier.train(positive_df_set + negative_df_set)\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "xT6VZHwsRIfB",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54ad188d00186fa78cee7fe25838015f",
          "grade": true,
          "grade_id": "2-3-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 2.3 for training the classifier\n",
        "\n",
        "classifier = build_classifier(pages_df, negative_df)\n",
        "print(type(classifier))\n",
        "\n",
        "# This should print <class 'nltk.classify.naivebayes.NaiveBayesClassifier'>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "Y3q7WyM7RVbW",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4e2c6be6bbb8f4d040730fd6b9d9d4dd",
          "grade": false,
          "grade_id": "cell-5805e1cdf30c9b1c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2.4: Run the classifier\n",
        "\n",
        "Below are some sample pages.  Let's see if you can run the model on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "senOL6iQHkim",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bea797c4c8a6db2d719817b7f16f3f26",
          "grade": false,
          "grade_id": "cell-f311584c5d0bf3ea",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 2.4.1 Load the test set\n",
        "\n",
        "Adapt the code from Task 2.1 for the new dataset. Call the final dataframe `inference_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "nVe0c3fHUK_x",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "106f80cc575d61741b6936ebffd833af",
          "grade": false,
          "grade_id": "2-4-1-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Create inference_df\n",
        "\n",
        "test = [\n",
        "    'https://fried.com/history-of-bitcoin/',\n",
        "    'https://news.wharton.upenn.edu/press-releases/2018/06/penn-launches-strategic-collaboration-ripple-accelerate-innovation-blockchain-cryptocurrency/',\n",
        "    'https://en.wikipedia.org/wiki/Euro',\n",
        "    'https://ew.com/movies/star-wars-rise-of-skywalker-footage-d23-expo/',\n",
        "    'https://en.wikipedia.org/wiki/Donald_Trump'\n",
        "]\n",
        "\n",
        "# YOUR CODE HERE\n",
        "inference = crawl(test)\n",
        "inference2 = []\n",
        "for site, content in inference.items():\n",
        "    article = clean_article(content)\n",
        "    inference2.append({'site': site, 'text': article})\n",
        "inference_df = pd.DataFrame(inference2)\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "qYm4ecTHReP7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5850ebe51ab457bc0c583995d08cb26a",
          "grade": true,
          "grade_id": "2-4-1-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 2.4.1 loading the test set\n",
        "\n",
        "display(inference_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "MxbQZplPR4Wg",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3d196a152ba322f3aad165163dd0857b",
          "grade": false,
          "grade_id": "cell-3b2c38ea6c280a25",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Task 2.4.2: Inference\n",
        "\n",
        "Now let's run your classifier over your individual documents. Adapt the code from the NLTK lecture notebook. The function classify should take as input a two column dataframe as we have made previously, the trained classifier, and an optional vocabulary list. It should return a list of booleans. For example, a perfect classifier should return\n",
        "\n",
        "`classify(inference_df, classifier) = [True, True, False, False, False]`.\n",
        "\n",
        "Note that you will need to run `get_words` (passing the vocabulary) and then generate an NLTK frequency distribution for each test article."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "lVEaAr4e6miy",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "42bda82c2761bed25308404f6892b0ff",
          "grade": false,
          "grade_id": "2-4-2-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Complete the classify function\n",
        "\n",
        "def classify(df, classifier, vocabulary=[]):\n",
        "  bool_list=[]\n",
        "  result_list=[]\n",
        "# YOUR CODE HERE\n",
        "  for text in df['text']:\n",
        "    text_set = nltk.FreqDist(get_words(text, vocabulary))\n",
        "    prob_result = classifier.prob_classify(text_set)\n",
        "    result_list.append(prob_result.max() == 'positive')\n",
        "  return result_list\n",
        "#raise NotImplementedError()\n",
        "\n",
        "results = classify(inference_df, classifier)\n",
        "display(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "1hlVt_58Q-mX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "faf46a0f3b717f482f24e7c4a83ef4de",
          "grade": true,
          "grade_id": "2-4-2-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 2.4.2 classifier results\n",
        "\n",
        "if len(results) != 5:\n",
        "    raise AssertionError('We do not have a classification for each item.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "mNKNSOuzQ-uz",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "30286da0920823bcc4533f76e1d07eb7",
          "grade": true,
          "grade_id": "2-4-2-test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 2.4.2 for autograding results  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "deletable": false,
        "editable": false,
        "id": "YNo9zZLb8WTY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8a426f8b0fcc42d86f54dedc6fe449a2",
          "grade": false,
          "grade_id": "cell-14b50a9757ed81bd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Task 2.5: Make the vocabulary and re-classify\n",
        "\n",
        "So far, our classifier is not very good. This is because it is trying to consider too many words, many of which did or did not occur in the training articles purely by chance. If we restrict the \"attention\" of the classifier to the most frequent words, it is much more likely to pick up real patterns rather than memorize accidents. We do this by making a vocabulary.\n",
        "\n",
        "Complete the `make_vocabulary` function below. This function should take as input the two column dataframes `positive_df` and `negative_df`, and also an integer `num`. For the positive dataframe, run `get_words` on each article (without vocabulary), concatenate all of these lists of words together, create an NLTK frequency distribution, and then finally store a list of the `num` most frequent words. Do the same for the negative dataframe. The function should return the `num` most frequent positive words and the `num` most frequent negative words concatenated into one list (2 times `num` words in all).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "id": "mOU-YpBE9u4a",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb49f0466f3b33ad3312c230f37c2a59",
          "grade": false,
          "grade_id": "2-5-ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# TODO: Complete the make_vocabulary function\n",
        "\n",
        "def make_vocabulary(positive_df, negative_df, num):\n",
        "  positive_df_set = []\n",
        "  negative_df_set = []\n",
        "# YOUR CODE HERE\n",
        "  for article_pos in positive_df['text']:\n",
        "    for words in get_words(article_pos):\n",
        "      positive_df_set.append((words))\n",
        "  for article_neg in negative_df['text']:\n",
        "    for word in get_words(article_neg):\n",
        "      negative_df_set.append((word))\n",
        "  return positive_df_set[0:30] + negative_df_set[0:30]\n",
        "#raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "Quri9yZn_fgv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1363795adb36e655a7ab9b635e66077c",
          "grade": true,
          "grade_id": "2-5-1-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 2.5.1 see final vocabulary size\n",
        "\n",
        "vocabulary = make_vocabulary(pages_df, negative_df, 30)\n",
        "print(len(vocabulary))\n",
        "#print(vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "eBjSQCfV_f7z",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0eefc8d89f5ca392f2b67c52473b336f",
          "grade": true,
          "grade_id": "2-5-2-sanity",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Sanity check 2.5 improved classifier results\n",
        "\n",
        "classifier_with_vocab = build_classifier(pages_df, negative_df, vocabulary)\n",
        "results = classify(inference_df, classifier_with_vocab, vocabulary)\n",
        "display(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "deletable": false,
        "editable": false,
        "id": "P2KobDFhHB0_",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "264c1983dd26f060d3ab2c6db272f98c",
          "grade": true,
          "grade_id": "2-5-test",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# Hidden tests 2.5 for autograding results  - please don't delete\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydELAEzkzpE_",
        "colab_type": "text"
      },
      "source": [
        "# Task 3: Submitting Your Homework\n",
        "\n",
        "1. When you are done, select “Edit” at the top of the window, **under the filename, not the one that may appear above it**. Then, select “Clear all outputs”. Please do this just before turning is your homework because it reduces the size of your file.\n",
        "\n",
        "\n",
        "2. In the same menu **under the filename**, select “File” and then “Download .ipynb”. It is very important that you do not change the file name of this downloaded notebook. Make sure that something like “(1)” did not get added to the filename and also that you did not download the .py version. Our autograder can only handle .ipynb files with the correct file name.\n",
        "\n",
        "3. Compress the ipynb file into a Zip file **hw1.zip**.\n",
        "\n",
        "4. Go to the [submission site](http://submit.dataanalytics.education), and click on the Google icon.  Log in using your Google@SEAS (if at all possible!) or (if you aren’t an Engineering student) GMail account.  \n",
        "\n",
        "5. Click on the **Courses** icon at the top, then select **CIS 545** and **Save**. Select **cis545-2019c-hw1** and upload **hw1.zip**.\n",
        "\n",
        "6. You should see a message on the submission site notifying you about whether your submission passed validation.  You may resubmit as necessary, but may have to withdraw your previous submission in OpenSubmit in order to do so.\n",
        "\n",
        "**If you have not already, please go to Settings and set your Student ID to your PennID (all numbers)**."
      ]
    }
  ]
}